{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (事前準備: OpenAI APIキーの設定)\n",
    "OpenAI APIを使う為のAPIキーを設定します  \n",
    "このAPIキーについては、OpenAIのサイトで取得することが出来ます  \n",
    "https://platform.openai.com/api-keys  \n",
    "APIキーについては公開しないように注意してください  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のリンクをクリックするとGoogle Colabで実行することが出来ます  \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/2Nike2/LangChainPractice/blob/main/00_03_use_retriever.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ここにあなたのOpenAIのAPIキーを入力してください\n",
    "openai_api_key = 'yourapikey'\n",
    "\n",
    "# 環境変数にAPIキーがまだ設定されていないならばAPIキーを設定\n",
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    os.environ['OPENAI_API_KEY'] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (事前準備: Tavily APIキーの設定)\n",
    "AIエージェントに適した、Tavilyの検索エンジンのAPIキーを設定します  \n",
    "https://app.tavily.com/home  \n",
    "APIキーについては公開しないように注意してください  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにあなたのOpenAIのAPIキーを入力してください\n",
    "tavily_api_key = 'yourapikey'\n",
    "\n",
    "# 環境変数にAPIキーがまだ設定されていないならばAPIキーを設定\n",
    "if os.getenv('TAVILY_API_KEY') is None:\n",
    "    os.environ['TAVILY_API_KEY'] = tavily_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エージェント\n",
    "LLMが使用出来るツールを登録して機能を拡張します\n",
    "ここでは予めダウンロードしてきた文書を検査するツールと、\n",
    "上記とは別にWebで動的に検索するツールを追加します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインストール\n",
    "LangChainのライブラリをインストールします  \n",
    "またWeb文書を取得するためのライブラリであるBeautifulSoup  \n",
    "及びベクトルデータベースのfaiss(CPU版)もインストールします  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.1.4\n",
    "!pip install langchain-openai==0.0.5\n",
    "!pip install beautifulsoup4==4.12.3\n",
    "!pip install faiss-cpu==1.7.4\n",
    "!pip install langchainhub==0.1.14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの初期化\n",
    "OpenAI APIを使う為のモデルを初期化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web文書の取得\n",
    "WebBaseLoaderを使ってWeb文書を取得します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.aozora.gr.jp/cards/000081/files/43754_17659.html\") # 青空文庫 「注文の多い料理店」(宮沢賢治)\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 埋め込みモデル\n",
    "埋め込みモデルを初期化します\n",
    "これは今まで使ってきた文章に対して文章を返すモデルと違い、文章に対して埋め込みベクトル(数百~数千個の数値のリスト)を返すモデルです  \n",
    "個の埋め込みベクトルというのは文章の意味を数値に要約したものと考えられ、複数の埋め込みベクトルの距離や角度を計算することによって文章の意味の近さを捉えられます  \n",
    "これを利用して指示や質問に対して意味が近かったり関連性が高い文章を探し出すことが出来ます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトルデータベースの用意\n",
    "上記の埋め込みベクトルを格納して高速に検索するためのベクトルデータベースを用意します  \n",
    "ベクトルデータベースに登録する文章は全体をそのまま入れるのではなく、何らかの単位(字数、章、ページ区切り等)で分割してからベクトル化して保存することになります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter()\n",
    "text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=800, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リトリーバの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever(search_kwargs={'k': 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ツールの登録\n",
    "ツールを登録します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得済みWeb文書リトリーバ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever, \n",
    "                                       'miyazawakenji_restaulant',\n",
    "                                       '宮沢賢治の「注文の多い料理店」について調べるツールです。宮沢賢治の「注文の多い料理店」に関する質問の場合はこのツールを使って答えて下さい。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI検索ツール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エージェントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "tools = [retriever_tool, search]\n",
    "\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({'input': '玄関の札に出ていたレストランの日本語名は？'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"現在のアメリカの大統領の名前は？\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
