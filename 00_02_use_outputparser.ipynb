{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のリンクをクリックするとGoogle Colabで実行することが出来ます  \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/2Nike2/LangChainPractice/blob/main/00_02_use_outputparser.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (事前準備: OpenAI APIキーの設定)\n",
    "OpenAI APIを使う為のAPIキーを設定します  \n",
    "このAPIキーについては、OpenAIのサイトで取得することが出来ます  \n",
    "https://platform.openai.com/api-keys  \n",
    "APIキーについては公開しないように注意してください  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ここにあなたのOpenAIのAPIキーを入力してください\n",
    "openai_api_key = 'yourapikey'\n",
    "\n",
    "# 環境変数にAPIキーがまだ設定されていないならばAPIキーを設定\n",
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    os.environ['OPENAI_API_KEY'] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出力パーサーの使い方\n",
    "LLMの出力を解析し、決められた形式で出力させる為の方法を確認します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインストール\n",
    "LangChainのライブラリをインストールします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai==0.1.4\n",
    "!pip install langchain-openai==0.0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの初期化\n",
    "OpenAI APIを使う為のモデルを初期化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力パーサーの定義\n",
    "出力パーサーを定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "stroutput_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チェインの作成  \n",
    "LLMのモデルを利用する際の一連の流れをチェインとして定義します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm | stroutput_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 普通にLLMを使う場合\n",
    "response1 = llm.invoke('こんにちは、元気ですか？')\n",
    "print('type(response1)', type(response1))\n",
    "print(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力パーサーを含むチェーンを使う場合\n",
    "response2 = chain.invoke('こんにちは、元気ですか？')\n",
    "print('type(response2)', type(response2))\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通にLLMを呼び出したときは、AIMessageクラスのインスタンス(文章の内容だけではなく、メッセージのタイプの情報も含む)が返ってくるが、StrOutputParserを使うと文字列が返ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### その他の出力パーサー\n",
    "単に出力を文字列にするだけではなく、CSV形式(Python上ではリストに変換)やJSON形式(Python上では辞書に変換)などにすることも出来る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSVパーサー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "# 出力パーサーの作成\n",
    "csv_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# チェインの作成\n",
    "csv_chain = llm | csv_parser\n",
    "\n",
    "# チェインの実行\n",
    "csv_chain_response = csv_chain.invoke('愛知県の観光名所をコンマ区切りで並べて。')\n",
    "print('type(csv_chain_response)', type(csv_chain_response))\n",
    "print('csv_chain_response')\n",
    "print('len(csv_chain_response)', len(csv_chain_response))\n",
    "pprint(csv_chain_response)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSONパーサー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "# 出力パーサーの作成\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# チェインの作成\n",
    "json_chain = llm | json_parser\n",
    "\n",
    "# チェインの実行\n",
    " \n",
    "json_chain_response = json_chain.invoke('明治の文豪をキー、代表作をバリューとするJSON形式のデータを作ってください。')\n",
    "print('type(json_chain_response)', type(json_chain_response))\n",
    "print('json_chain_response')\n",
    "print('len(json_chain_response)', len(json_chain_response))\n",
    "pprint(json_chain_response)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
